import matplotlib.pyplot as plt
import torch
from scripts import ResultsGNN, EmbeddingSpace
from sklearn.manifold import TSNE
from sklearn.preprocessing import StandardScaler
from typing import Dict
import warnings


class Plot:
    def __init__(self):
        self.figsize = (12, 8)
        self.title_size = 18
        self.label_size = 16
        self.dpi = 800
    
    def loss_history(self, data: ResultsGNN, outfile: str = None):
        plt.figure(figsize=self.figsize)

        plt.plot(data.n_epochs, data.loss_history, color='blue', label='training')
        plt.plot(data.n_epochs, data.validation_loss_history, color='red', label='validation')

        plt.title('Loss history', fontsize=self.title_size)
        plt.xlabel('loss', fontsize=self.label_size)
        plt.ylabel('epochs', fontsize=self.label_size)
        plt.legend()

        plt.gca().spines['top'].set_visible(False)
        plt.gca().spines['left'].set_visible(False)
        plt.gca().spines['right'].set_visible(False)

        if outfile:
            plt.savefig(outfile, dpi=self.dpi)
            plt.close()
        else:
            plt.show()

    def embedding_space(self, data: ResultsGNN, outfile: str = None):
        """
        Generate a 1x3 figure of the embedding space generated by the GNN aglorithm.

        :param data: ResultsGNN object provided as the output of  `run_gnn`
        :param outfile: result file to save the output
        """
        # node type colors
        my_colors = ['#386641', '#6A994E', '#A7C957', '#BC4749',]

        # data processing
        def run_tsne(emb_dict: EmbeddingSpace) -> Dict[str, torch.Tensor]:
            """
            Concatenate the different node types and then perform t-sne. Afterwards split them again
            for different coloring.

            :param emb_dict: Embedding dictionary object, output provided by the GNN.
            :return: Dimensionally reduced embedding space for 2D plotting.
            """
            results = {}
            nt_order, nt_sizes = ['xxx',], {'xxx': 0,}
            my_tensor = None

            # concatenate the embeddings spaces to be normalized and t-sned together
            for node_type in emb_dict.node_types:
                tmp_tensor = emb_dict(node_type=node_type)
                nt_sizes[node_type] = tmp_tensor.shape[0] + nt_sizes[nt_order[-1]]
                nt_order.append(node_type)
                if my_tensor == None:
                    my_tensor = tmp_tensor
                else:
                    tensor_tup = (my_tensor, tmp_tensor)
                    my_tensor = torch.cat(tensor_tup, dim=0)
            # apply a t-sne dimensionality reduction
            tsne_res = my_tsne(x=my_tensor)

            # split again after t-sne
            for i in range(1, len(nt_order)):
                results[nt_order[i]] = my_tensor[nt_sizes[nt_order[i-1]]:nt_sizes[nt_order[i]], :]

            return results


        # perform t-sne per set
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')
            #
            if data.training_embedding_space:
                training_data = run_tsne(emb_dict=data.training_embedding_space)
            if data.validation_embedding_space:
                validation_data = run_tsne(emb_dict=data.validation_embedding_space)
            if data.test_embedding_space:
                test_data = run_tsne(emb_dict=data.test_embedding_space)

        # Create a figure and three subplots side by side
        fig, axes = plt.subplots(1, 3, figsize=self.figsize)

        #
        if data.training_embedding_space:
            for i, (node_type, dims) in enumerate(training_data.items()):
                axes[0].scatter(dims[:, 0], dims[:, 1], color=my_colors[i], edgecolors='b', label=node_type)
            axes[0].set_title('Training set')
            axes[0].set_xlabel('dim 1')
            axes[0].set_ylabel('dim 2')
            axes[0].legend()

        if data.validation_embedding_space:
            for i, (node_type, dims) in enumerate(validation_data.items()):
                axes[1].scatter(dims[:, 0], dims[:, 1], color=my_colors[i], edgecolors='b', label=node_type)
            axes[1].set_title('Validation set')
            axes[1].set_xlabel('dim 1')
            axes[1].set_ylabel('dim 2')
            axes[1].legend()

        if data.test_embedding_space:
            for i, (node_type, dims) in enumerate(test_data.items()):
                axes[2].scatter(dims[:, 0], dims[:, 1], color=my_colors[i], edgecolors='b', label=node_type)
            axes[2].set_title('Test set')
            axes[2].set_xlabel('dim 1')
            axes[2].set_ylabel('dim 2')
            axes[2].legend()

        if outfile:
            plt.savefig(outfile, dpi=self.dpi)
            plt.close()
        else:
            plt.show()


def my_tsne(x: torch.Tensor) -> torch.Tensor:
    """
    Performs t-sne to reduce the dimensionality of input `x` to 2D.
    :param x: NxF torch tensor, N is the number of samples, F is the number of features
    :return: Nx2 torch tensor
    """
    # Standardize the features
    scaler = StandardScaler()
    x_scaled = scaler.fit_transform(x)

    # Apply t-SNE for dimensionality reduction to 2D
    tsne = TSNE(n_components=2, perplexity=30, random_state=71)
    x_embedded = tsne.fit_transform(x_scaled)

    return x_embedded
